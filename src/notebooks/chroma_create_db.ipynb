{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "import chromadb\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\": {\n",
    "        \"data_dir\": r\"data\\pdfs\",\n",
    "        \"persist_directory\": \"chroma_langchain_db\",\n",
    "    },\n",
    "    \"train\": {\n",
    "        \"output_document_from_vector_store\": 5,\n",
    "        \"chunk_size\": 1000,\n",
    "        \"chunk_overlap\": 10,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"embedding_model\": \"mxbai-embed-large\",\n",
    "        \"llm_model\": \"smollm:1.7b\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the Path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"__file__\").resolve().parent.parent.parent / config[\"data\"][\"data_dir\"]\n",
    "persist_directory = (\n",
    "    Path(\"__file__\").resolve().parent.parent.parent / config['data'][\"persist_directory\"]\n",
    ")\n",
    "config[\"data\"][\"data_dir\"] = data_dir\n",
    "config['data'][\"persist_directory\"] = persist_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'data_dir': WindowsPath('D:/Python/InsightAI/data/pdfs'),\n",
       "  'persist_directory': WindowsPath('D:/Python/InsightAI/chroma_langchain_db')},\n",
       " 'train': {'output_document_from_vector_store': 5,\n",
       "  'chunk_size': 1000,\n",
       "  'chunk_overlap': 10},\n",
       " 'model': {'embedding_model': 'mxbai-embed-large', 'llm_model': 'smollm:1.7b'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_mapping_dict = {\n",
    "    \"c0\": \"Alienware alpha or Alienware steam machine\",\n",
    "    \"c1\": \"XPS 27 7760\",\n",
    "    \"c2\": \"Alienware 13 R3\",\n",
    "    \"c3\": \"Dell Alienware m16 R1\",\n",
    "    \"c4\": \"Alienware m17 R4\",\n",
    "    \"c5\": \"Alienware x17 R2\",\n",
    "    \"c6\": \"Chromebook 11 3180\",\n",
    "    \"c7\": \"Dell G15 5510\",\n",
    "    \"c8\": \"ASUS ROG Strix SCAR 17 (2023)\",\n",
    "    \"c9\": \"ROG Zephyrus G16 (2024) GU605\",\n",
    "    \"c10\": \"Dell XPS 13 9370\",\n",
    "    \"c11\": \"Dell XPS 14 9440\",\n",
    "    \"c12\": \"Dell XPS 15 9500\",\n",
    "    \"c13\": \"Dell XPS 16 9640\",\n",
    "    \"c14\": \"XPS 17 9730\",\n",
    "    \"c15\": \"Dell Alienware m16 R2\",\n",
    "    \"c16\": \"Alienware x14 R2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='c:\\\\Users\\\\sugam\\\\AppData\\\\Local\\\\pypoetry\\\\Cache\\\\virtualenvs\\\\insightai-WytcrPNm-py3.12\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='c:\\\\Users\\\\sugam\\\\AppData\\\\Local\\\\pypoetry\\\\Cache\\\\virtualenvs\\\\insightai-WytcrPNm-py3.12\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='c:\\\\Users\\\\sugam\\\\AppData\\\\Local\\\\pypoetry\\\\Cache\\\\virtualenvs\\\\insightai-WytcrPNm-py3.12\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n",
      "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
      "DEBUG:httpx:load_verify_locations cafile='c:\\\\Users\\\\sugam\\\\AppData\\\\Local\\\\pypoetry\\\\Cache\\\\virtualenvs\\\\insightai-WytcrPNm-py3.12\\\\Lib\\\\site-packages\\\\certifi\\\\cacert.pem'\n"
     ]
    }
   ],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=config['model'][\"embedding_model\"],\n",
    ")\n",
    "\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "# llm = ChatOllama(model=config['model'][\"llm_model\"], callbacks=callback_manager)\n",
    "llm = ChatOllama(model=config['model'][\"llm_model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT RUN THE CELL BELOW Twice!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Iterate over the data directory. Splits the pdf's and returns list of documents.\n",
    "    Args\n",
    "    ----\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    documents: list\n",
    "        List of splitted documents.\n",
    "    \"\"\"\n",
    "\n",
    "    documents: list = []\n",
    "\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "\n",
    "        chunk_size=config[\"train\"][\"chunk_size\"],\n",
    "\n",
    "        chunk_overlap=config[\"train\"][\"chunk_overlap\"],\n",
    "\n",
    "        length_function=len,\n",
    "    )\n",
    "\n",
    "    class_abbreviation: list[str] = os.listdir(config['data'][\"data_dir\"])\n",
    "\n",
    "\n",
    "    for item in tqdm(class_abbreviation):\n",
    "\n",
    "        path_till_individual_folder: str = config['data'][\"data_dir\"] / item\n",
    "\n",
    "        for individual_pdf in os.listdir(path_till_individual_folder):\n",
    "\n",
    "            actual_name_pdf: str = class_name_mapping_dict[item].strip()\n",
    "\n",
    "            loader = PyPDFLoader(\n",
    "                os.path.join(path_till_individual_folder, individual_pdf)\n",
    "            )\n",
    "\n",
    "            temp_docs = loader.load()\n",
    "\n",
    "            splitted_docs = text_splitter.split_documents(temp_docs)\n",
    "\n",
    "            for doc in splitted_docs:\n",
    "                doc.metadata[\"category\"] = actual_name_pdf\n",
    "                doc.metadata.pop(\"source\")\n",
    "                doc.metadata.pop(\"page\")\n",
    "\n",
    "            documents.extend(splitted_docs)\n",
    "\n",
    "    logger.info(f\"The total length of the extracted pdf: {len(documents)}\")\n",
    "    return documents\n",
    "\n",
    "documents = get_data()\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "DEBUG:chromadb.config:Starting component System\n",
      "DEBUG:chromadb.config:Starting component Posthog\n",
      "DEBUG:chromadb.config:Starting component OpenTelemetryClient\n",
      "DEBUG:chromadb.config:Starting component SqliteDB\n",
      "DEBUG:chromadb.config:Starting component QuotaEnforcer\n",
      "DEBUG:chromadb.config:Starting component LocalSegmentManager\n",
      "DEBUG:chromadb.config:Starting component SegmentAPI\n",
      "DEBUG:chromadb.api.segment:Collection InsightAICollection already exists, returning existing collection.\n",
      "DEBUG:chromadb.api.segment:Collection test_collection already exists, returning existing collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): us.i.posthog.com:443\n",
      "DEBUG:urllib3.connectionpool:https://us.i.posthog.com:443 \"POST /batch/ HTTP/11\" 200 15\n"
     ]
    }
   ],
   "source": [
    "# Initiate Vector Store\n",
    "persistent_client = chromadb.PersistentClient(path=str(config['data'][\"persist_directory\"]))\n",
    "collection = persistent_client.get_or_create_collection(\"InsightAICollection\")\n",
    "vector_store_from_client = Chroma(\n",
    "    client=persistent_client,\n",
    "    collection_name=\"test_collection\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1727855055407903300"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persistent_client.heartbeat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment the below cell to add documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc, uuid in tqdm(zip(documents, uuids), total=len(documents), desc=\"Adding documents\"):\n",
    "#     vector_store_from_client.add_documents(documents=[doc], ids=[uuid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the RAM of the model?\"\n",
    "image_class = \"Alienware alpha or Alienware steam machine\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC01F78710>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 02 Oct 2024 07:47:46 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 02 Oct 2024 07:47:46 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Specifications Views\\nSystem  \\nInformationMemoryPorts and  \\nConnectorsDimensions and \\nWeightStorage Communications Video Audio\\nPower AdapterComputer \\nEnvironmentMemory\\nConnector Two SODIMM slots\\nType DDR3L\\nSpeed 1600 MHz\\nConfigurations supported 2 GB, 4 GB, 8 GB, and 16 GB'), 0.5036019086837769), (Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Specifications Views\\nSystem  \\nInformationMemoryPorts and  \\nConnectorsDimensions and \\nWeightStorage Communications Video Audio\\nPower AdapterComputer \\nEnvironmentVideo\\nController NVIDIA GeForce GPU\\nMemory 2 GB GDDR5'), 0.6564028859138489), (Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Specifications Views\\nSystem  \\nInformationMemoryPorts and  \\nConnectorsDimensions and \\nWeightStorage Communications Video Audio\\nPower AdapterComputer \\nEnvironmentSystem Information\\nComputer model Alienware Alpha\\nProcessor • 4th Generation Intel Dual Core i3\\n• 4th Generation Intel Quad Core i5\\n• 4th Generation Intel Quad Core i7 \\nChipset Intel H81\\nDMI speed 5.0 GT/s\\nProcessor data width 64 bits'), 0.6812134981155396), (Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Main\\nBIOS Revision Displays the BIOS version number.\\nBIOS Build Date Displays the BIOS release date.\\nSystem Name Displays the system name.\\nSystem Time Displays the current time in \\nhh:mm:ss format.\\nSystem Date Displays the current date in \\nmm/dd/yyy format.\\nService Tag Displays the service tag of your \\ncomputer.\\nService Tag Input Allows you to enter the service tag of \\nyour computer.\\nAsset Tag Displays the asset tag of your \\ncomputer.\\nProcessor Information\\nProcessor Type Displays the processor type.\\nProcessor ID Displays the processor identification \\ncode.\\nProcessor Core Count Displays the number of cores in the \\nprocessor.\\nProcessor L1 Cache Displays the processor L1 cache size.\\nProcessor L2 Cache Displays the processor L2 cache size.\\nProcessor L3 Cache Displays the processor L3 cache size.\\nMemory Information\\nMemory Installed Displays the total computer \\nmemory.\\nMemory Available Displays the amount of memory \\navailable on the computer.\\nMemory Running Speed Displays the memory speed.'), 0.6828691959381104), (Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Memory Technology Displays the type of memory \\ntechnology used.\\nSATA Information\\n75'), 0.7122282981872559)]\n",
      "[Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Specifications Views\\nSystem  \\nInformationMemoryPorts and  \\nConnectorsDimensions and \\nWeightStorage Communications Video Audio\\nPower AdapterComputer \\nEnvironmentMemory\\nConnector Two SODIMM slots\\nType DDR3L\\nSpeed 1600 MHz\\nConfigurations supported 2 GB, 4 GB, 8 GB, and 16 GB'), Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Specifications Views\\nSystem  \\nInformationMemoryPorts and  \\nConnectorsDimensions and \\nWeightStorage Communications Video Audio\\nPower AdapterComputer \\nEnvironmentVideo\\nController NVIDIA GeForce GPU\\nMemory 2 GB GDDR5'), Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Specifications Views\\nSystem  \\nInformationMemoryPorts and  \\nConnectorsDimensions and \\nWeightStorage Communications Video Audio\\nPower AdapterComputer \\nEnvironmentSystem Information\\nComputer model Alienware Alpha\\nProcessor • 4th Generation Intel Dual Core i3\\n• 4th Generation Intel Quad Core i5\\n• 4th Generation Intel Quad Core i7 \\nChipset Intel H81\\nDMI speed 5.0 GT/s\\nProcessor data width 64 bits'), Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Main\\nBIOS Revision Displays the BIOS version number.\\nBIOS Build Date Displays the BIOS release date.\\nSystem Name Displays the system name.\\nSystem Time Displays the current time in \\nhh:mm:ss format.\\nSystem Date Displays the current date in \\nmm/dd/yyy format.\\nService Tag Displays the service tag of your \\ncomputer.\\nService Tag Input Allows you to enter the service tag of \\nyour computer.\\nAsset Tag Displays the asset tag of your \\ncomputer.\\nProcessor Information\\nProcessor Type Displays the processor type.\\nProcessor ID Displays the processor identification \\ncode.\\nProcessor Core Count Displays the number of cores in the \\nprocessor.\\nProcessor L1 Cache Displays the processor L1 cache size.\\nProcessor L2 Cache Displays the processor L2 cache size.\\nProcessor L3 Cache Displays the processor L3 cache size.\\nMemory Information\\nMemory Installed Displays the total computer \\nmemory.\\nMemory Available Displays the amount of memory \\navailable on the computer.\\nMemory Running Speed Displays the memory speed.'), Document(metadata={'category': 'Alienware alpha or Alienware steam machine'}, page_content='Memory Technology Displays the type of memory \\ntechnology used.\\nSATA Information\\n75')]\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = vector_store_from_client.similarity_search_with_score(\n",
    "    query=query, k=5, filter={\"category\": image_class}\n",
    ")\n",
    "query_embeddings = embeddings.embed_query(query)\n",
    "retrieved_docs_from_embeddings = vector_store_from_client.similarity_search_by_vector(\n",
    "    query_embeddings, k=5, filter={\"category\": image_class}\n",
    ")\n",
    "print(retrieved_docs)\n",
    "print(retrieved_docs_from_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC01F7B650>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=utf-8'), (b'Date', b'Wed, 02 Oct 2024 07:47:59 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='127.0.0.1' port=11434 local_address=None timeout=None socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AC01F7B6B0>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Wed, 02 Oct 2024 07:48:27 GMT'), (b'Transfer-Encoding', b'chunked')])\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the steps to remove the base cover ?\"\n",
    "image_class = \"Dell Alienware m16 R1\"\n",
    "retriever = vector_store_from_client.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 5, \"filter\": {\"category\": image_class}},\n",
    ")\n",
    "retrived_query = retriever.invoke(query)\n",
    "formatated_docs = \"\\n\\n\".join(doc.page_content for doc in retrived_query)\n",
    "response = llm.invoke(f\"\"\"You are an assistant for question-answering tasks.\n",
    "            Use the following pieces context to answer the question.\n",
    "            If the context does not contain answer, just say that you don't know. Do not add anything on your own.\\n\\n\n",
    "            Question: {query}\n",
    "           Context:{formatated_docs}\n",
    "           \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the answer to your question:\n",
      "\n",
      "**Question:** What are the steps to remove the base cover ?\n",
      "\n",
      "**Context:** Major components of Alienware m16 R1 ...............................\n",
      "Base cover ...............................\n",
      "Removing the base cover ...............\n",
      "Installing the base cover ...............\n",
      "\n",
      "1.Remove the six screws (M2.5x5) that secure the base cover to the palm-rest and keyboard assembly.\n",
      "2.Loosen the two captive screws (M2.5x8) that secure the base cover to the palm-rest and keyboard assembly.\n",
      "3.Using a plastic scribe, pry the base cover from the bottom left and continue to work on the sides to open the base cover.\n",
      "4.Slide and lift the base cover off the palm-rest and keyboard assembly.\n",
      "5.Peel the tape that secures the battery cable to the battery.\n",
      "6.Disconnect the battery cable from the system board.\n",
      "\n",
      "**Steps:**\n",
      "\n",
      "1. Remove the base cover .\n",
      "2. Follow the procedure in After working inside your computer .\n",
      "3. Remove the base cover .\n",
      "4. Remove the battery .\n",
      "5. Remove the speakers .\n",
      "\n",
      "Note: The steps provided are based on the context of the question and may not be applicable to all questions or contexts.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
